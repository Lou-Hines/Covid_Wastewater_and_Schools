{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d54189d",
   "metadata": {},
   "source": [
    "# Preprocessing and Modelling Pre-Omicron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b58c067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import csv \n",
    "from collections import Counter\n",
    "import datetime\n",
    "import holidays\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, StandardScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from patsy import dmatrices\n",
    "\n",
    "from lineartree import LinearTreeRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, explained_variance_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b57b813",
   "metadata": {},
   "source": [
    "#### When first modelling, I had one notebook. I ran the first linear models against the original data and just the school-aged population and school status columns. Below, I am running them with all my engineered features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f372efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        72091.0\n",
       "1       122994.0\n",
       "2       117865.0\n",
       "3       151282.0\n",
       "4       131881.0\n",
       "          ...   \n",
       "1479     46435.0\n",
       "1480     33636.0\n",
       "1481     29986.0\n",
       "1482     74748.0\n",
       "1483    240219.0\n",
       "Name: School-Aged Population, Length: 1484, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_pre_omi = pd.read_csv('data/pre_omi.csv')\n",
    "\n",
    "merged_df_pre_omi['Test Date'] = pd.to_datetime(merged_df_pre_omi['Test Date'])\n",
    "\n",
    "merged_df_pre_omi['School Status'] = merged_df_pre_omi['School Status'].astype('object')\n",
    "merged_df_pre_omi['School-Aged Population']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fecc95",
   "metadata": {},
   "source": [
    "#### Simple preprocessing. Not going to worry about scaling right now. Just attempting to determine if my features are  strong enough to warrant continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b24ebeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRRF Name\n",
      "Per Capita Gene Copies\n",
      "Population Served, estimated\n",
      "School Status\n",
      "School-Aged Population\n",
      "Season\n"
     ]
    }
   ],
   "source": [
    "cat_cols = []\n",
    "\n",
    "for i in merged_df_pre_omi.columns:\n",
    "    if i == 'Gene Copies (N1/L)' or i == 'Test Date' or i == 'Holiday' or i == 'Sample Date':\n",
    "        pass\n",
    "    elif merged_df_pre_omi[i].dtype == 'object':\n",
    "        cat_cols.append(i)\n",
    "        print(i)\n",
    "    elif merged_df_pre_omi[i].dtype == 'float64' or merged_df_pre_omi[i].dtype == 'int64':\n",
    "        print(i)\n",
    "    else:\n",
    "        print(\"error\")\n",
    "\n",
    "\n",
    "cat_transformer = Pipeline(steps=[  \n",
    "    ('cat_encoder', OneHotEncoder(handle_unknown='ignore'))                     \n",
    "])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_transformer, cat_cols),\n",
    "    ])\n",
    "\n",
    "y = merged_df_pre_omi['Gene Copies (N1/L)']\n",
    "\n",
    "X = merged_df_pre_omi.drop('Gene Copies (N1/L)', axis=1)\n",
    "\n",
    "X_train ,X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2575b6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5587991188685084"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up columns to be onehot encoded. We will look at numerical transformation later\n",
    "\n",
    "Have to drop the NaNs, otherwise linear model won't work\n",
    "y_train = y_train.dropna()\n",
    "X_train = X_train.dropna()\n",
    "X_test = X_test.dropna()\n",
    "y_test = y_test.dropna()\n",
    "\n",
    "linreg = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred=linreg.predict(X_test)\n",
    "\n",
    "linreg.score(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29cea349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Date: -1070.2982270060952\n",
      "Test Date: 1000.1580037146778\n",
      "WRRF Name: 1133.043333951316\n",
      "Per Capita Gene Copies: -729.9289403163428\n",
      "Population Served, estimated: 3534.929886399773\n",
      "School Status: -1595.292150257837\n",
      "School-Aged Population: -2604.654484580207\n",
      "Season: 1246.104726306294\n",
      "Holiday: 6245.974160965021\n"
     ]
    }
   ],
   "source": [
    "linear_model = linreg.named_steps['model']\n",
    "\n",
    "# Print the coefficients along with column names\n",
    "for feature_name, coef in zip(X.columns, linear_model.coef_):\n",
    "    print(f\"{feature_name}: {coef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6302d2",
   "metadata": {},
   "source": [
    "#### Let's try again but with log-transformed targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "035362af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Date: -0.0440007780691526\n",
      "Test Date: 0.20732123218866916\n",
      "WRRF Name: 0.19162232107698013\n",
      "Per Capita Gene Copies: -0.14624733932704054\n",
      "Population Served, estimated: 0.31736815887438546\n",
      "School Status: -0.1297000508508879\n",
      "School-Aged Population: -0.3831365358061128\n",
      "Season: 0.4055824921338149\n",
      "Holiday: 0.7947331217220195\n"
     ]
    }
   ],
   "source": [
    "linear_model = linreg_2.named_steps['model']\n",
    "\n",
    "# Print the coefficients along with column names\n",
    "for feature_name, coef in zip(X.columns, linear_model.coef_):\n",
    "    print(f\"{feature_name}: {coef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16cdc06",
   "metadata": {},
   "source": [
    "#### With the addition of jewish holidays, got a 1% boost in the r2 score. Might get a little nudge with Islamic, but probably not much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b780c",
   "metadata": {},
   "source": [
    "#### Trying without the highly-correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "359e13a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6177258476117596"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_df = merged_df_pre_omi.copy()\n",
    "\n",
    "copy_df.dropna(inplace=True)\n",
    "\n",
    "y = copy_df['Gene Copies (N1/L)']\n",
    "\n",
    "\n",
    "X = copy_df.drop(columns=['Gene Copies (N1/L)','Population Served, estimated', 'Per Capita Gene Copies'], axis=1)\n",
    "\n",
    "# Split again\n",
    "X_train ,X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "# Log transforming the target\n",
    "\n",
    "y_test = np.log(y_test)\n",
    "y_train = np.log(y_train)\n",
    "\n",
    "# 3rd iteration, no adjustments to the model itself\n",
    "\n",
    "linreg_3 = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "linreg_3.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linreg_3.predict(X_test)\n",
    "\n",
    "linreg_3.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4eb1bc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Date: -0.14757150645203634\n",
      "Test Date: 0.17730798873563733\n",
      "WRRF Name: 0.21434747417862648\n",
      "School Status: -0.1206607271795389\n",
      "School-Aged Population: 0.28797817715926266\n",
      "Season: -0.1298456319366709\n",
      "Holiday: -0.3610885764908265\n"
     ]
    }
   ],
   "source": [
    "linear_model = linreg_3.named_steps['model']\n",
    "\n",
    "# Print the coefficients along with column names\n",
    "for feature_name, coef in zip(X.columns, linear_model.coef_):\n",
    "    print(f\"{feature_name}: {coef}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f237d8c4",
   "metadata": {},
   "source": [
    "#### Slightly worse score without the non-school population data. So even though it's correlated, the general population data is not boosting the score much. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7e0888",
   "metadata": {},
   "source": [
    "#### Let's look at just the school-related data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4773f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df_2 = merged_df_pre_omi.copy()\n",
    "copy_df_2.dropna(inplace=True)\n",
    "\n",
    "y = copy_df_2['Gene Copies (N1/L)']\n",
    "\n",
    "X = copy_df_2[['School-Aged Population', 'School Status']]\n",
    "\n",
    "\n",
    "# We only have one column to transform in this version\n",
    "\n",
    "cat_cols_2 = ['School Status']\n",
    "\n",
    "preprocessor_2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_transformer, cat_cols_2),\n",
    "    ])\n",
    "\n",
    "X_train ,X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05cb26cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46997170371988195"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4th model - this one is actually different!\n",
    "\n",
    "linreg_4 = Pipeline([\n",
    "    ('preprocessor', preprocessor_2),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "linreg_4.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linreg_4.predict(X_test)\n",
    "\n",
    "linreg_4.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e94bd8",
   "metadata": {},
   "source": [
    "#### With just the school-aged population and school status, our model explains nearly half the variance! And this is before log transformation!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2e9d4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5422711234817856\n",
      "0.5143954687950946\n"
     ]
    }
   ],
   "source": [
    "# Same model, log-transformed target data.\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)\n",
    "\n",
    "linreg_5 = Pipeline([\n",
    "    ('preprocessor', preprocessor_2),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "linreg_5.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linreg_5.predict(X_test)\n",
    "\n",
    "print(linreg_5.score(X_train,y_train))\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533ac82c",
   "metadata": {},
   "source": [
    "#### Ok, our train tests scores are pretty close! Not too much overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6996df1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New X and y\n",
    "\n",
    "copy_df_3 = merged_df_pre_omi.copy()\n",
    "copy_df_3.dropna(inplace=True)\n",
    "y = copy_df_3['Gene Copies (N1/L)']\n",
    "\n",
    "X = copy_df_3['School-Aged Population']\n",
    "\n",
    "\n",
    "# Split again\n",
    "\n",
    "X_train ,X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# log transform again\n",
    "\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)\n",
    "\n",
    "# using ols because we are not preprocessing this data\n",
    "X_int = sm.add_constant(X_train)\n",
    "results = sm.OLS(y_train, X_int).fit()\n",
    "summary = results.summary()\n",
    "print(summary)\n",
    "\n",
    "influence = OLSInfluence(results)\n",
    "print(influence.resid_studentized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffaa2e9",
   "metadata": {},
   "source": [
    "#### Well, this isn't very good! This is just school-aged population, though, and not the actual status of schools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e40ac36",
   "metadata": {},
   "source": [
    "#### Wonder how predictive the baseline model is. Let's just look at the original population data, which is one ofthe most relevant features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd2bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df_4 = merged_df_pre_omi.copy()\n",
    "copy_df_4.dropna(inplace=True)\n",
    "\n",
    "y = copy_df_4['Gene Copies (N1/L)']\n",
    "X = copy_df_4['Population Served, estimated']\n",
    "\n",
    "X_train ,X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)\n",
    "\n",
    "X_int = sm.add_constant(X_train)\n",
    "model_2 = sm.OLS(y_train, X_int).fit()\n",
    "\n",
    "summary = model_2.summary()\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df_5 = merged_df_pre_omi.copy()\n",
    "copy_df_5.dropna(inplace=True)\n",
    "y = copy_df_5['Gene Copies (N1/L)']\n",
    "\n",
    "X = copy_df_5[['Population Served, estimated', 'WRRF Name', 'Per Capita Gene Copies', 'Sample Date', 'Test Date']]\n",
    "\n",
    "X_train ,X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa973bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols_3 = ['WRRF Name']\n",
    "\n",
    "cat_transformer = Pipeline(steps=[  \n",
    "    ('cat_encoder', OneHotEncoder(handle_unknown='ignore'))                     \n",
    "])\n",
    "\n",
    "preprocessor_3 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_transformer, cat_cols_3),\n",
    "    ])\n",
    "\n",
    "linreg_6 = Pipeline([\n",
    "    ('preprocessor', preprocessor_3),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "linreg_6.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linreg_6.predict(X_test)\n",
    "\n",
    "print(linreg_6.score(X_train,y_train))\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422696cb",
   "metadata": {},
   "source": [
    "#### So yeah, the basic info from the original dataset explains almost nothing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a99305a",
   "metadata": {},
   "source": [
    "#### Want to use the index (sample date) as a feature*. Let's also save this data file as a csv, since it's what we ultimately want to use.\n",
    "* Was originally attempting to model as time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d39e1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_date_df = merged_df_pre_omi.copy()\n",
    "sample_date_df['Sample Date'] = pd.to_datetime(sample_date_df['Sample Date'])\n",
    "\n",
    "# sample_date_df.to_csv('data/master_wastewater.csv', index=False)\n",
    "\n",
    "#(Ending up abandoning dates as features, but in future work would like to integrate them.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360cee4d",
   "metadata": {},
   "source": [
    "#### Fancier models! Going to move on to more elaborate models, including Random Forest. Re-doing the columns for preprocessing since we have different features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f040b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = []\n",
    "cat_cols = []  \n",
    "num_cols = []   \n",
    "\n",
    "for i in sample_date_df.columns:\n",
    "    if i == 'Gene Copies (N1/L)' or i == 'Holiday':\n",
    "        pass\n",
    "    elif sample_date_df[i].dtype == 'datetime64[ns]':\n",
    "        date_cols.append(i)\n",
    "    elif sample_date_df[i].dtype == 'object':\n",
    "        cat_cols.append(i)\n",
    "    elif i == 'Sample Date':\n",
    "        date_cols.append(i)\n",
    "    elif sample_date_df[i].dtype == 'float64' or sample_date_df[i].dtype == 'int64':\n",
    "        num_cols.append(i)\n",
    "    else:\n",
    "        print(\"error\")\n",
    "        \n",
    "\n",
    "\n",
    "print(date_cols)\n",
    "print(cat_cols)\n",
    "print(num_cols)\n",
    "# leaving \"holiday\" out because we don't want to transform this binary data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbfb080",
   "metadata": {},
   "source": [
    "#### Custom function Allows for fit and transformation of linear features in a pipeline. Were originally trying to combineLinearRegressor with RandomForest using FeatureUnion, but was unsuccessful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin): \n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.columns]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0185f6c",
   "metadata": {},
   "source": [
    "#### Just going with a vanilla Random Forest model after trying to combine a linear regression and random forest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c50c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New X and y, split\n",
    "\n",
    "sample_copy_df = sample_date_df.copy()\n",
    "sample_copy_df.dropna(inplace=True)\n",
    "\n",
    "X = sample_copy_df.drop('Gene Copies (N1/L)', axis=1)\n",
    "\n",
    "y = sample_copy_df['Gene Copies (N1/L)']\n",
    "\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)\n",
    "\n",
    "# New preprocessors\n",
    "\n",
    "cat_preprocessor = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numeric_preprocessor = Pipeline([\n",
    "    ('selector', ColumnSelector(columns=num_cols)), \n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_preprocessor, cat_cols),\n",
    "    ('num', numeric_preprocessor, num_cols),\n",
    "])\n",
    "\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model',  RandomForestRegressor(random_state = 42))\n",
    "])\n",
    "\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = rf_pipeline.predict(X_test)\n",
    "\n",
    "print(f'R-squared score on training data: {rf_pipeline.score(X_train, y_train)}')\n",
    "print(f'R2 test score: {r2_score(y_test, y_pred)}')\n",
    "print(f'Mean squared error: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute percentage error: {mean_absolute_percentage_error(y_test, y_pred)}')\n",
    "print(f'Explained variance score (modified R2): {explained_variance_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9724a0",
   "metadata": {},
   "source": [
    "#### Wow, 99.5%!  Let's look at feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5f936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf_pipeline.named_steps['model']\n",
    "features = []\n",
    "scores = []\n",
    "\n",
    "# Print the coefficients along with column names\n",
    "for feature_name, importance in zip(X.columns, rf_model.feature_importances_):\n",
    "    features.append(feature_name)\n",
    "    scores.append(importance)\n",
    "    \n",
    "ranked_scores = sorted(zip(scores, features), reverse=True)\n",
    "for score, feature in ranked_scores:\n",
    "    print(f'{score}: {feature}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ade2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate(rf_pipeline, X_train, y_train, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9decb6",
   "metadata": {},
   "source": [
    "#### Want to try this model again without the date features, since they seem to be over-determining.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59823e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_copy_df_2 = sample_date_df.copy()\n",
    "\n",
    "sample_copy_df_2.dropna(inplace=True)\n",
    "\n",
    "X = sample_copy_df_2.drop(['Gene Copies (N1/L)', 'Sample Date', 'Test Date'], axis=1)\n",
    "\n",
    "y = sample_copy_df_2['Gene Copies (N1/L)']\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)\n",
    "\n",
    "date_cols = []\n",
    "cat_cols = []  \n",
    "num_cols = []   \n",
    "\n",
    "for i in sample_date_df.columns:\n",
    "    if i == 'Gene Copies (N1/L)' or i == 'Holiday':\n",
    "        pass\n",
    "    elif sample_date_df[i].dtype == 'datetime64[ns]':\n",
    "        date_cols.append(i)\n",
    "    elif sample_date_df[i].dtype == 'object':\n",
    "        cat_cols.append(i)\n",
    "    elif i == 'Sample Date':\n",
    "        date_cols.append(i)\n",
    "    elif sample_date_df[i].dtype == 'float64' or sample_date_df[i].dtype == 'int64':\n",
    "        num_cols.append(i)\n",
    "    else:\n",
    "        print(\"error\")\n",
    "        \n",
    "\n",
    "\n",
    "print(date_cols)\n",
    "print(cat_cols)\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f8691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding in numeric scaling\n",
    "\n",
    "cat_preprocessor = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numeric_preprocessor = Pipeline([\n",
    "    ('selector', ColumnSelector(columns=num_cols)), \n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_preprocessor, cat_cols),\n",
    "    ('num', numeric_preprocessor, num_cols),\n",
    "])\n",
    "\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model',  RandomForestRegressor(random_state = 42))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)  # Same pipeline, different data\n",
    "\n",
    "\n",
    "y_pred = rf_pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "print(f'R-squared score on training data: {rf_pipeline.score(X_train, y_train)}')\n",
    "print(f'R2 test score: {r2_score(y_test, y_pred)}')\n",
    "print(f'Mean squared error: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute percentage error: {mean_absolute_percentage_error(y_test, y_pred)}')\n",
    "print(f'Explained variance score (modified R2): {explained_variance_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a616a81",
   "metadata": {},
   "source": [
    "#### The very same! Our engineered features are very strong all around. Let's look at feature importance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf_pipeline.named_steps['model']\n",
    "features = []\n",
    "scores = []\n",
    "# Print the coefficients along with column names\n",
    "for feature_name, importance in zip(X.columns, rf_model.feature_importances_):\n",
    "    features.append(feature_name)\n",
    "    scores.append(importance)\n",
    "    \n",
    "ranked_scores = sorted(zip(scores, features), reverse=True)\n",
    "for score, feature in ranked_scores:\n",
    "    print(f'{score}: {feature}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efce553",
   "metadata": {},
   "source": [
    "#### Let's try another model type, using all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e83afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_copy_df = sample_date_df.copy()\n",
    "\n",
    "X = sample_copy_df.drop('Gene Copies (N1/L)', axis=1)\n",
    "\n",
    "y = sample_copy_df['Gene Copies (N1/L)']\n",
    "\n",
    "X.dropna(inplace=True)\n",
    "y.dropna(inplace=True)\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)\n",
    "\n",
    "grad = GradientBoostingRegressor()\n",
    "\n",
    "grad_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model',  grad)\n",
    "])\n",
    "\n",
    "\n",
    "grad_pipeline.fit(X_train, y_train)\n",
    "y_pred = grad_pipeline.predict(X_test)\n",
    "\n",
    "print(f'R-squared score on training data: {grad_pipeline.score(X_train, y_train)}')\n",
    "print(f'R2 test score: {r2_score(y_test, y_pred)}')\n",
    "print(f'Mean squared error: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute percentage error: {mean_absolute_percentage_error(y_test, y_pred)}')\n",
    "print(f'Explained variance score (modified R2 test score): {explained_variance_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55c8eaf",
   "metadata": {},
   "source": [
    "#### Pretty similar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae966026",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_model = grad_pipeline.named_steps['model']\n",
    "features = []\n",
    "scores = []\n",
    "# Print the coefficients along with column names\n",
    "for feature_name, importance in zip(X.columns, grad_model.feature_importances_):\n",
    "    features.append(feature_name)\n",
    "    scores.append(importance)\n",
    "    \n",
    "ranked_scores = sorted(zip(scores, features), reverse=True)\n",
    "for score, feature in ranked_scores:\n",
    "    print(f'{score}: {feature}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeac608e",
   "metadata": {},
   "source": [
    "#### Very different weighing of features here, and slightly better test score. Let's look at loss scores, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189dfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = grad_pipeline['model'].train_score_\n",
    "train_score\n",
    "\n",
    "# If we ran maybe double the iteratations, our loss score should approach .2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccc29b1",
   "metadata": {},
   "source": [
    "#### Let's get rid of all date features with this model and see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61753617",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_copy_df = sample_date_df.copy()\n",
    "\n",
    "X = sample_copy_df.drop(columns=['Gene Copies (N1/L)','Sample Date', 'Test Date'], axis=1)\n",
    "\n",
    "y = sample_copy_df['Gene Copies (N1/L)']\n",
    "\n",
    "X.dropna(inplace=True)\n",
    "y.dropna(inplace=True)\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)\n",
    "\n",
    "grad = GradientBoostingRegressor()\n",
    "grad_best_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model',  grad)\n",
    "])\n",
    "\n",
    "grad_best_pipeline.fit(X_train, y_train)\n",
    "y_pred = grad_best_pipeline.predict(X_test)\n",
    "\n",
    "print(f'R-squared score on training data: {grad_best_pipeline.score(X_train, y_train)}')\n",
    "print(f'R2 test score: {r2_score(y_test, y_pred)}')\n",
    "print(f'Mean squared error: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute percentage error: {mean_absolute_percentage_error(y_test, y_pred)}')\n",
    "print(f'Explained variance score (modified R2 test score): {explained_variance_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72b6992",
   "metadata": {},
   "source": [
    "#### Very similar scores, with less over-fitting. Good! Let's examine feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135bd58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_model = grad_best_pipeline.named_steps['model']\n",
    "features = []\n",
    "scores = []\n",
    "# Print the coefficients along with column names\n",
    "for feature_name, importance in zip(X.columns, grad_model.feature_importances_):\n",
    "    features.append(feature_name)\n",
    "    scores.append(importance)\n",
    "    \n",
    "ranked_scores = sorted(zip(scores, features), reverse=True)\n",
    "for score, feature in ranked_scores:\n",
    "    print(f'{score}: {feature}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff37a623",
   "metadata": {},
   "source": [
    "#### Going to remove highly-correlated non-engineered features, to better see how strong the model is with my contibutions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1383b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_copy_df = sample_date_df.copy()\n",
    "\n",
    "sample_copy_df.dropna(inplace=True)\n",
    "\n",
    "X = sample_copy_df.drop(columns=['Gene Copies (N1/L)','Sample Date', 'Test Date', 'Population Served, estimated', 'Per Capita Gene Copies'], axis=1)\n",
    "\n",
    "y = sample_copy_df['Gene Copies (N1/L)']\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)\n",
    "\n",
    "# Re-do preprocesing as we have different features\n",
    "date_cols = []\n",
    "cat_cols = []  \n",
    "num_cols = []   \n",
    "\n",
    "for i in sample_date_df.columns:\n",
    "    if i == 'Gene Copies (N1/L)' or i == 'Holiday' or i == 'Population Served, estimated' or i == 'Per Capita Gene Copies':\n",
    "        pass\n",
    "    elif sample_date_df[i].dtype == 'datetime64[ns]':\n",
    "        date_cols.append(i)\n",
    "    elif sample_date_df[i].dtype == 'object':\n",
    "        cat_cols.append(i)\n",
    "    elif i == 'Sample Date':\n",
    "        date_cols.append(i)\n",
    "    elif sample_date_df[i].dtype == 'float64' or sample_date_df[i].dtype == 'int64':\n",
    "        num_cols.append(i)\n",
    "    else:\n",
    "        print(\"error\")\n",
    "        \n",
    "\n",
    "\n",
    "print(date_cols)\n",
    "print(cat_cols)\n",
    "print(num_cols)\n",
    "# leaving \"holiday\" out because we don't want to transform this binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fef3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_transformer = Pipeline(steps=[  \n",
    "    ('cat_encoder', OneHotEncoder(handle_unknown='ignore'))                     \n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_transformer, cat_cols),\n",
    "    ])\n",
    "\n",
    "grad = GradientBoostingRegressor()\n",
    "grad_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model',  grad)\n",
    "])\n",
    "\n",
    "grad_pipeline.fit(X_train, y_train)\n",
    "y_pred = grad_pipeline.predict(X_test)\n",
    "\n",
    "print(f'R-squared score on training data: {grad_pipeline.score(X_train, y_train)}')\n",
    "print(f'R2 test score: {r2_score(y_test, y_pred)}')\n",
    "print(f'Mean squared error: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "print(f'Mean absolute percentage error: {mean_absolute_percentage_error(y_test, y_pred)}')\n",
    "print(f'Explained variance score (modified R2 test score): {explained_variance_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f005e33b",
   "metadata": {},
   "source": [
    "#### Looking at feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f29db9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_model = grad_pipeline.named_steps['model']\n",
    "features = []\n",
    "scores = []\n",
    "# Print the coefficients along with column names\n",
    "for feature_name, importance in zip(X.columns, grad_model.feature_importances_):\n",
    "    features.append(feature_name)\n",
    "    scores.append(importance)\n",
    "    \n",
    "ranked_scores = sorted(zip(scores, features), reverse=True)\n",
    "for score, feature in ranked_scores:\n",
    "    print(f'{score}: {feature}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9381e723",
   "metadata": {},
   "source": [
    "#### Analysis: \n",
    "\n",
    "By removing correlated features, our score was reduced dramatically. However, there seem to be important elements of the non-date correlated features that we should keep, because although they are similar, they tell us important things about the data at particular times (as opposed to our scores, which cover the entire data period). For instance, sudden wastewater spikes around school events in places with high school-aged populations. Over time, these effects are expected to flatten out and/or become more cyclical. One avenue to pursue later would be population estimates of those who left the city during 2020/2021 but who were never officially non-residents, and thus not reflected in the Census Bureau's data. We would expect much more of this in wealthier zipcodes and in zipcodes where there are fewer children. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf3b285",
   "metadata": {},
   "source": [
    "#### Setting up for grid search of our best model so far. Re-doing preprocessing since using different features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6992721",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = []\n",
    "cat_cols = []  \n",
    "num_cols = []   \n",
    "\n",
    "for i in sample_date_df.columns:\n",
    "    if i == 'Gene Copies (N1/L)' or i == 'Holiday':\n",
    "        pass\n",
    "    elif sample_date_df[i].dtype == 'datetime64[ns]':\n",
    "        date_cols.append(i)\n",
    "    elif sample_date_df[i].dtype == 'object':\n",
    "        cat_cols.append(i)\n",
    "    elif i == 'Sample Date':\n",
    "        date_cols.append(i)\n",
    "    elif sample_date_df[i].dtype == 'float64' or sample_date_df[i].dtype == 'int64':\n",
    "        num_cols.append(i)\n",
    "    else:\n",
    "        print(\"error\")\n",
    "        \n",
    "print(date_cols)\n",
    "print(cat_cols)\n",
    "print(num_cols)\n",
    "\n",
    "cat_preprocessor = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numeric_preprocessor = Pipeline([\n",
    "    ('selector', ColumnSelector(columns=num_cols)), \n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_preprocessor, cat_cols),\n",
    "    ('num', numeric_preprocessor, num_cols),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecda4225",
   "metadata": {},
   "source": [
    "#### Removing the datetime info and running grid search on our best model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ddb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_copy_df = sample_date_df.copy()\n",
    "sample_copy_df.dropna(inplace=True)\n",
    "\n",
    "X = sample_copy_df.drop(columns=['Gene Copies (N1/L)','Sample Date', 'Test Date'], axis=1)\n",
    "\n",
    "y = sample_copy_df['Gene Copies (N1/L)']\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "y_train = np.log(y_train)\n",
    "\n",
    "y_test = np.log(y_test)\n",
    "\n",
    "grad = GradientBoostingRegressor()\n",
    "\n",
    "param_grid = {\n",
    "    'model__learning_rate': [.01, .1, .3],\n",
    "    'model__loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "    'model__n_estimators': [100, 150, 200, 250],\n",
    "    'model__subsample': [.3, .5, .7, 1.0],\n",
    "    'model__criterion': ['friedman_mse', 'squared_error']\n",
    "    \n",
    "}\n",
    "                            \n",
    "grid_search_gbc = GridSearchCV(\n",
    "    estimator = grad_best_pipeline, \n",
    "    param_grid = param_grid,\n",
    "    cv= 5,\n",
    "    scoring='explained_variance' \n",
    ")\n",
    "\n",
    "grid_search_gbc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search_gbc.predict(X_test)\n",
    "\n",
    "cv_score = grid_search_gbc.best_score_\n",
    "test_score = r2_score(y_test, grid_search_gbc.predict(X_test))\n",
    "\n",
    "\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print(grid_search_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083dd9d8",
   "metadata": {},
   "source": [
    "#### Grid Search feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d03503",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_gbc.best_estimator_\n",
    "\n",
    "model_step = best_model.named_steps['model']\n",
    "print(model_step)\n",
    "\n",
    "feature_importances = model_step.feature_importances_\n",
    "\n",
    "features = []\n",
    "scores = []\n",
    "\n",
    "for feature_name, importance in zip(X.columns, feature_importances):\n",
    "    features.append(feature_name)\n",
    "    scores.append(importance)\n",
    "    \n",
    "ranked_scores = sorted(zip(scores, features), reverse=True)\n",
    "for score, feature in ranked_scores:\n",
    "    print(f'{score}: {feature}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fa4e62",
   "metadata": {},
   "source": [
    "\n",
    "#### Visualize residuals for our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4a1d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred, color='blue')\n",
    "sns.regplot(x=y_test, y=y_pred, color='red', scatter=False)\n",
    "\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Pre-Omicron Actual vs. Predicted Values')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Normalize the residuals\n",
    "scaler = StandardScaler()\n",
    "residuals_normalized = scaler.fit_transform(residuals.values.reshape(-1, 1))\n",
    "\n",
    "# Create a linear regression object\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Fit the linear regression to the data\n",
    "linreg.fit(y_pred.reshape(-1,1), residuals_normalized)\n",
    "\n",
    "# Create predicted values for the trendline\n",
    "trendline = linreg.predict(y_pred.reshape(-1,1))\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals_normalized, alpha=0.5)\n",
    "plt.plot(y_pred, trendline, color='red')\n",
    "plt.title('Normalized Residuals vs Fitted Values')\n",
    "plt.xlabel('Fitted values')\n",
    "plt.ylabel('Normalized residuals')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Histogram of Residuals (Pre-Omicron)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals (Pre-Omicron)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, np.sqrt(np.abs(residuals)), alpha=0.5)\n",
    "plt.title('Scale-Location Plot (Pre-Omicron)')\n",
    "plt.xlabel('Fitted values')\n",
    "plt.ylabel('sqrt(|standardized residuals|)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33d2b0b",
   "metadata": {},
   "source": [
    "#### Thought I was done, but want to try one more model type: LinearTrees!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5927df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_copy_df = sample_date_df.copy()\n",
    "\n",
    "# sample_copy_df.dropna(inplace=True)\n",
    "\n",
    "# X = sample_copy_df.drop(columns=['Gene Copies (N1/L)','Sample Date', 'Test Date'], axis=1)\n",
    "\n",
    "# y = sample_copy_df['Gene Copies (N1/L)']\n",
    "\n",
    "# X_train,X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "# y_train = np.log(y_train)\n",
    "# y_test = np.log(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a8d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lintree = LinearTreeRegressor(base_estimator=LinearRegression())\n",
    "\n",
    "# lintree_pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('to_sparse', FunctionTransformer(csr_matrix, validate=False)),  # convert to sparse\n",
    "#     ('to_dense', FunctionTransformer(lambda x: x.toarray(), validate=False)), # convert to dense. lintree requires this\n",
    "#     ('model',  lintree)\n",
    "# ])\n",
    "\n",
    "# lintree_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = lintree_pipeline.predict(X_test)\n",
    "\n",
    "# print(f'R-squared score on training data: {lintree_pipeline.score(X_train, y_train)}')\n",
    "# print(f'R2 test score: {r2_score(y_test, y_pred)}')\n",
    "# print(f'Mean squared error: {mean_squared_error(y_test, y_pred)}')\n",
    "# print(f'Mean absolute error: {mean_absolute_error(y_test, y_pred)}')\n",
    "# print(f'Mean absolute percentage error: {mean_absolute_percentage_error(y_test, y_pred)}')\n",
    "# print(f'Explained variance score (modified R2 test score): {explained_variance_score(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8266e72",
   "metadata": {},
   "source": [
    "\n",
    "### Well, that was a terrible model for this data, but seemed interesting! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MCMPrime)",
   "language": "python",
   "name": "mcmprime"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
