{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21c975c8",
   "metadata": {},
   "source": [
    "# Now we're going to see how well our pre-Omicron model lines up against post-Omicron data, roughly established to have begun circulating November 2021 in NYC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082ff82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<style>.container { width:80% !important;}</style>'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49c3bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import zscore, rankdata, kendalltau\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import csv \n",
    "from collections import Counter\n",
    "import datetime\n",
    "import holidays\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, StandardScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from patsy import dmatrices\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, explained_variance_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14585a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_omi_df = pd.read_csv('data/SARS-CoV-2_concentrations_measured_in_NYC_Wastewater.csv')\n",
    "\n",
    "post_omi_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2074c8de",
   "metadata": {},
   "source": [
    "### Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e992afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fetching file to compute total school-aged population from (See Pre-Omicron EDA file)\n",
    "\n",
    "merged_df = pd.read_csv('data/merged_zip_data.csv')\n",
    "\n",
    "\n",
    "# Setting datetime features\n",
    "post_omi_df['Sample Date'] = pd.to_datetime(post_omi_df['Sample Date'])\n",
    "\n",
    "# Filter the dataframe to include only dates after a certain date\n",
    "\n",
    "post_omi_df = post_omi_df[post_omi_df['Sample Date'] > '2021-10-31']\n",
    "\n",
    "# Drop same columns as before\n",
    "\n",
    "post_omi_df.drop(columns=['Annotation', 'Test date', 'WRRF Abbreviation'], inplace=True)\n",
    "\n",
    "# Merge school pop and zipcode data \n",
    "\n",
    "post_omi_df['Total WRRF School-Aged Pop'] = post_omi_df['WRRF Name'].map(merged_df.groupby('WRRF Name')['Total WRRF Population'].first())\n",
    "\n",
    "# Save as csv. We are ultimately going to be working with 4 csvs and want to keep each step separate.\n",
    "post_omi_df.to_csv('data/merged_df_post_omi.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece186e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_post_omi = pd.read_csv('data/merged_df_post_omi.csv')\n",
    "\n",
    "# converting to datetime again? Unsure why I have to do this twice\n",
    "\n",
    "merged_df_post_omi['Sample Date'] = pd.to_datetime(merged_df_post_omi['Sample Date'])\n",
    "\n",
    "# Exploring nulls\n",
    "\n",
    "merged_df_post_omi.isnull().sum()\n",
    "\n",
    "# Drop nulls since so few\n",
    "\n",
    "merged_df_post_omi.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c73d23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few visualizations. We already have a good idea of the general contours of this data and expect it to \n",
    "# diverge from pre-omicron\n",
    "\n",
    "\n",
    "sns.histplot(data=merged_df_post_omi, x='Concentration SARS-CoV-2 gene target (N1 Copies/L) ', kde=True)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "sns.barplot(data=merged_df_post_omi, x='WRRF Name', y='Total WRRF School-Aged Pop')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(data=merged_df_post_omi, x='WRRF Name', y='Concentration SARS-CoV-2 gene target (N1 Copies/L) ')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sns.scatterplot(data=merged_df_post_omi, x='Concentration SARS-CoV-2 gene target (N1 Copies/L) ', y='Population Served, estimated ')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "corr = merged_df_post_omi.corr()\n",
    "\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1247d6",
   "metadata": {},
   "source": [
    "# Modelling Post-Omicron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e75a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Removing date info since we decided before that it is too over-determining. We are only keeping the School-aged Population info\n",
    "# from our engineered features, since the others would need to be re-created for this time period.\n",
    "\n",
    "X = merged_df_post_omi.drop(columns=['Concentration SARS-CoV-2 gene target (N1 Copies/L) ', 'Sample Date'], axis=1)\n",
    "y = merged_df_post_omi['Concentration SARS-CoV-2 gene target (N1 Copies/L) ']\n",
    "\n",
    "\n",
    "\n",
    "X_train_2 ,X_test_2, y_train_2, y_test_2 = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# log transform\n",
    "y_train_2 = np.log(y_train_2)\n",
    "y_test_2 = np.log(y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c0a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we would like to go back and add in seasons, holidays, etc for this period, but out of curiosity, let's\n",
    "# see how our model works on just this data. We want to do the same transformations as before, but our features\n",
    "# are a bit different, so let's account for that.\n",
    "\n",
    "\n",
    "# Re-doing the columns \n",
    "date_cols = []\n",
    "cat_cols = []  \n",
    "num_cols = []   \n",
    "\n",
    "for i in merged_df_post_omi.columns:\n",
    "    if i == 'Concentration SARS-CoV-2 gene target (N1 Copies/L) ' or i == 'Sample Date':\n",
    "        pass\n",
    "    elif merged_df_post_omi[i].dtype == 'object':\n",
    "        cat_cols.append(i)\n",
    "    elif merged_df_post_omi[i].dtype == 'float64' or 'int64':\n",
    "        num_cols.append(i)\n",
    "    else:\n",
    "        print(\"error\")\n",
    "        \n",
    "class ColumnSelector(BaseEstimator, TransformerMixin): \n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.columns]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f5ce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using same prepocessing and parameters as our best pre-Omicron model\n",
    "\n",
    "cat_preprocessor = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numeric_preprocessor = Pipeline([\n",
    "    ('selector', ColumnSelector(columns=num_cols)), \n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_preprocessor, cat_cols),\n",
    "    ('num', numeric_preprocessor, num_cols),\n",
    "])\n",
    "\n",
    "grad_2 = GradientBoostingRegressor(criterion='squared_error', learning_rate=0.1, loss='absolute_error', n_estimators=150, subsample=0.5, random_state=42)\n",
    "\n",
    "\n",
    "grad_2_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model',  grad_2)\n",
    "])\n",
    "\n",
    "grad_2_pipeline.fit(X_train_2, y_train_2)\n",
    "\n",
    "y_pred_2 = grad_2_pipeline.predict(X_test_2)\n",
    "\n",
    "train_score = grad_2_pipeline.score(X_train_2, y_train_2)\n",
    "print(train_score)\n",
    "\n",
    "test_score = r2_score(y_test_2, y_pred_2)\n",
    "print(test_score)\n",
    "\n",
    "cross_validate(grad_2_pipeline, X_train_2, y_train_2, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c5e579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not horrible over all!\n",
    "\n",
    "# Let's visualize! Want to look at real vs predicted values as well as residuals and their distributions\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test_2, y=y_pred_2)\n",
    "plt.xlabel('Actual Values')\n",
    "\n",
    "\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs. Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c697726",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test_2 - y_pred_2\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals, bins=30, kde=True)\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d47c49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole bunch of plots analyzing residuals. We want to better understand how this model performs on data from\n",
    "# the post-Omicron period, and how and where it may be overfitting.\n",
    "\n",
    "\n",
    "# calculate residuals\n",
    "residuals_2 = y_test_2 - y_pred_2\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred_2, residuals_2, alpha=0.5)\n",
    "plt.title('Residuals vs Fitted Values (Post-Omicron)')\n",
    "plt.xlabel('Fitted values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals_2, kde=True)\n",
    "plt.title('Histogram of Residuals (Post-Omicron)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "stats.probplot(residuals_2, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals (Post-Omicron)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred_2, np.sqrt(np.abs(residuals_2)), alpha=0.5)\n",
    "plt.title('Scale-Location Plot (Post-Omicron)')\n",
    "plt.xlabel('Fitted values')\n",
    "plt.ylabel('sqrt(|standardized residuals|)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93289b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_post_omi.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2641bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize this some more. We didn't properly address outliers with pre-omicron features. \n",
    "copy = merged_df_post_omi.copy()\n",
    "copy.drop(columns=['Concentration SARS-CoV-2 gene target (N1 Copies/L) ', 'Sample Date'], inplace=True)\n",
    "copy.hist(figsize = (15,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e583c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1849968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to calculate z-scores and outliers greater than 3 stds\n",
    "def identify_outliers(df, column):\n",
    "    z_scores = zscore(df[column])\n",
    "    df['z_scores'] = z_scores\n",
    "    outliers = df[(df['z_scores'] > 3) | (df['z_scores'] < -3)]\n",
    "    return outliers\n",
    "\n",
    "outliers_1 = identify_outliers(copy, 'Population Served, estimated ')\n",
    "outliers_2 = identify_outliers(copy, 'Per capita SARS-CoV-2 load (N1 copies per day per population)')\n",
    "outliers_3 = identify_outliers(copy, 'Total WRRF School-Aged Pop')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "sns.boxplot(x=copy['Population Served, estimated '])\n",
    "plt.title('Boxplot of Population Served, estimated')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "sns.boxplot(x=copy['Per capita SARS-CoV-2 load (N1 copies per day per population)'])\n",
    "plt.title('Boxplot of Per capita SARS-CoV-2 load (N1 copies per day per population)')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "sns.boxplot(x=copy['Total WRRF School-Aged Pop'])\n",
    "plt.title('Boxplot of Total WRRF School-Aged Pop')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80041ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Going to try again using sklearn.preprocessing.RobustScaler. Seems like might be useful given outliers? Especially\n",
    "# with regards to our per capita feature.\n",
    "\n",
    "\n",
    "X = merged_df_post_omi.drop(columns=['Concentration SARS-CoV-2 gene target (N1 Copies/L) ', 'Sample Date'], axis=1)\n",
    "y = merged_df_post_omi['Concentration SARS-CoV-2 gene target (N1 Copies/L) ']\n",
    "\n",
    "\n",
    "\n",
    "X_train ,X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# log transform\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)\n",
    "\n",
    "# Re-adjusting data types for preprocessing\n",
    "cat_cols = []  \n",
    "num_cols = []   \n",
    "\n",
    "for i in merged_df_post_omi.columns:\n",
    "    if i == 'Concentration SARS-CoV-2 gene target (N1 Copies/L) ' or i == 'Holiday' or i == 'Sample Date':\n",
    "        pass\n",
    "    elif merged_df_post_omi[i].dtype == 'object':\n",
    "        cat_cols.append(i)\n",
    "    elif merged_df_post_omi[i].dtype == 'float64' or merged_df_post_omi[i].dtype == 'int64':\n",
    "        num_cols.append(i)\n",
    "    else:\n",
    "        print(\"error\")\n",
    "        \n",
    "print(cat_cols)\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87c565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting preprocessing steps\n",
    "\n",
    "numeric_preprocessor_2 = Pipeline([\n",
    "    ('selector', ColumnSelector(columns=num_cols)), \n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "preprocessor_4 = ColumnTransformer([   # This is our 4th preprocesser!\n",
    "    ('cat', cat_preprocessor, cat_cols),\n",
    "    ('num', numeric_preprocessor_2, num_cols),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Using our best pre-Omicron model as before\n",
    "\n",
    "grad_3 = GradientBoostingRegressor(criterion='squared_error', learning_rate=0.1, loss='absolute_error', n_estimators=150, subsample=0.5, random_state=42)\n",
    "grad_3_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_4),\n",
    "    ('model',  grad_3)\n",
    "])\n",
    "\n",
    "grad_3_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_3 = grad_3_pipeline.predict(X_test)\n",
    "\n",
    "train_score = grad_3_pipeline.score(X_train, y_train)\n",
    "print(train_score)\n",
    "\n",
    "test_score = r2_score(y_test, y_pred_3)\n",
    "print(test_score)\n",
    "\n",
    "cross_validate(grad_3_pipeline, X_train, y_train, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387dd536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting preprocessing columns for post-omi\n",
    "\n",
    "cat_cols = []  \n",
    "num_cols = []   \n",
    "\n",
    "for i in merged_df_post_omi.columns:\n",
    "    if i == 'Concentration SARS-CoV-2 gene target (N1 Copies/L) ':\n",
    "        pass\n",
    "    elif merged_df_post_omi[i].dtype == 'object':\n",
    "        cat_cols.append(i)\n",
    "    elif i == 'Sample Date':\n",
    "        pass\n",
    "    elif merged_df_post_omi[i].dtype == 'float64' or 'int64':\n",
    "        num_cols.append(i)\n",
    "    else:\n",
    "        print(\"error\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e4e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almost identical test/train scores for RobustScaler, so apparently our outliers are not too extreme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929327c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we just drop the total population served? Let's check out vif scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d217ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to rename 'Total WRRF School-Aged Pop' due to conflict with hyphen\n",
    "\n",
    "merged_df_post_omi.rename({'Total WRRF School-Aged Pop': 'Total WRRF Schoolaged Pop'},axis=1, inplace=True)\n",
    "\n",
    "merged_df_post_omi.columns = merged_df_post_omi.columns.str.replace(' ', '_', regex=True).str.replace('-', '_', regex=True).str.replace(',', '', regex=True).str.replace('(', '', regex=True).str.replace(')', '', regex=True).str.replace('/', '', regex=True).str.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b728386",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices('Concentration_SARS_CoV_2_gene_target_N1_CopiesL_ ~ Population_Served_estimated_+Total_WRRF_Schoolaged_Pop', data=merged_df_post_omi, return_type='dataframe')\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif['variable'] = X.columns\n",
    "\n",
    "vif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65461e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alright, very high VIFs, bud still don't want to removee this data. Would be nice to break it down by age groups within\n",
    "# school-age children as we originally sourced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df5ef97",
   "metadata": {},
   "source": [
    "# Feature Engineering for Post-Omicron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeafcdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to reset index to date to match it against holidays\n",
    "merged_df_post_omi.set_index('Sample_Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d45aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holidays: Federal US Holidays\n",
    "\n",
    "\n",
    "us_holidays = holidays.UnitedStates(years=[2021, 2022, 2023])\n",
    "\n",
    "def is_holiday(date):\n",
    "    return date in us_holidays\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c34920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holidays: Jewish Holidays \n",
    "\n",
    "# Major Jewish Holidays, 2021\n",
    "us_holidays[datetime.date(2021, 11, 28)] = 'Chanukah'\n",
    "us_holidays[datetime.date(2021, 11, 29)] = 'Chanukah'\n",
    "us_holidays[datetime.date(2021, 11, 30)] = 'Chanukah'\n",
    "us_holidays[datetime.date(2021, 12, 1)] = 'Chanukah'\n",
    "us_holidays[datetime.date(2021, 12, 2)] = 'Chanukah'\n",
    "us_holidays[datetime.date(2021, 12, 3)] = 'Chanukah'\n",
    "us_holidays[datetime.date(2021, 12, 4)] = 'Chanukah'\n",
    "us_holidays[datetime.date(2021, 12, 5)] = 'Chanukah'\n",
    "us_holidays[datetime.date(2021, 12, 6)] = 'Chanukah'\n",
    "\n",
    "# Major Jewish Holidays, 2022\n",
    "us_holidays[datetime.date(2022, 3, 16)] = 'Purim'\n",
    "us_holidays[datetime.date(2022, 3, 17)] = 'Purim'\n",
    "us_holidays[datetime.date(2022, 4, 15)] = 'Passover'\n",
    "us_holidays[datetime.date(2022, 4, 16)] = 'Passover'\n",
    "us_holidays[datetime.date(2022, 4, 17)] = 'Passover'\n",
    "us_holidays[datetime.date(2022, 4, 18)] = 'Passover'\n",
    "us_holidays[datetime.date(2022, 4, 19)] = 'Passover'\n",
    "us_holidays[datetime.date(2022, 4, 20)] = 'Passover'\n",
    "us_holidays[datetime.date(2022, 4, 21)] = 'Passover'\n",
    "us_holidays[datetime.date(2022, 4, 22)] = 'Passover'\n",
    "us_holidays[datetime.date(2022, 4, 23)] = 'Passover'\n",
    "us_holidays[datetime.date(2022, 6, 4)] = 'Shauvot'\n",
    "us_holidays[datetime.date(2022, 6, 5)] = 'Shauvot'\n",
    "us_holidays[datetime.date(2022, 6, 6)] = 'Shauvot'\n",
    "us_holidays[datetime.date(2022, 9, 25)] = 'Rosh Hashanah'\n",
    "us_holidays[datetime.date(2022, 9, 26)] = 'Rosh Hashanah'\n",
    "us_holidays[datetime.date(2022, 9, 27)] = 'Rosh Hashanah'\n",
    "us_holidays[datetime.date(2022, 10, 4)] = 'Yom Kippur'\n",
    "us_holidays[datetime.date(2022, 10, 5)] = 'Yom Kippur'\n",
    "us_holidays[datetime.date(2022, 10, 9)] = 'Sukkot'\n",
    "us_holidays[datetime.date(2022, 10, 10)] = 'Sukkot'\n",
    "us_holidays[datetime.date(2022, 10, 11)] = 'Sukkot'\n",
    "us_holidays[datetime.date(2022, 10, 12)] = 'Sukkot'\n",
    "us_holidays[datetime.date(2022, 10, 13)] = 'Sukkot'\n",
    "us_holidays[datetime.date(2022, 10, 14)] = 'Sukkot'\n",
    "us_holidays[datetime.date(2022, 10, 15)] = 'Sukkot'\n",
    "us_holidays[datetime.date(2022, 10, 16)] = 'Sukkot'\n",
    "us_holidays[datetime.date(2022, 12, 18)] = 'Chanukah'\n",
    "us_holidays[datetime.date(2022, 12, 19)] = 'Chanukah'\n",
    "us_holidays[datetime.date(2022, 12, 20)] = 'Chanukah'\n",
    "us_holidays[datetime.date(2022, 12, 21)] = 'Chanukah'\n",
    "us_holidays[datetime.date(2022, 12, 22)] = 'Chanukah'\n",
    "us_holidays[datetime.date(2022, 12, 23)] = 'Chanukah'\n",
    "us_holidays[datetime.date(2022, 12, 24)] = 'Chanukah'\n",
    "us_holidays[datetime.date(2022, 12, 25)] = 'Chanukah'\n",
    "us_holidays[datetime.date(2022, 12, 26)] = 'Chanukah'\n",
    "\n",
    "\n",
    "# Major Jewish holidays, 2023\n",
    "us_holidays[datetime.date(2023, 3, 6)] = 'Purim'\n",
    "us_holidays[datetime.date(2023, 3, 7)] = 'Purim'\n",
    "us_holidays[datetime.date(2023, 4, 5)] = 'Passover'\n",
    "us_holidays[datetime.date(2023, 4, 6)] = 'Passover'\n",
    "us_holidays[datetime.date(2023, 4, 7)] = 'Passover'\n",
    "us_holidays[datetime.date(2023, 4, 8)] = 'Passover'\n",
    "us_holidays[datetime.date(2023, 4, 9)] = 'Passover'\n",
    "us_holidays[datetime.date(2023, 4, 10)] = 'Passover'\n",
    "us_holidays[datetime.date(2023, 4, 11)] = 'Passover'\n",
    "us_holidays[datetime.date(2023, 4, 12)] = 'Passover'\n",
    "us_holidays[datetime.date(2023, 4, 13)] = 'Passover'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da19e634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsure how 1970 got in there, but our filter will filter out anything not in our date range\n",
    "merged_df_post_omi['Holiday'] = merged_df_post_omi.index.map(is_holiday).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466ad1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_post_omi['Holiday'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2319cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add seasons again. Keeping the index for now\n",
    "\n",
    "def get_season(date):\n",
    "    if date.strftime('%Y-%m-%d') >= '2021-03-20' and date.strftime('%Y-%m-%d') <= '2021-06-19':\n",
    "        return 'Spring 2021'\n",
    "    elif date.strftime('%Y-%m-%d') >= '2021-06-20' and date.strftime('%Y-%m-%d') <= '2021-09-21':\n",
    "        return 'Summer 2021'\n",
    "    elif date.strftime('%Y-%m-%d') >= '2021-09-22' and date.strftime('%Y-%m-%d') <= '2021-12-20':\n",
    "        return 'Fall 2021'\n",
    "    elif date.strftime('%Y-%m-%d') >= '2021-12-21' and date.strftime('%Y-%m-%d') <= '2022-03-19':\n",
    "        return 'Winter 2021'\n",
    "    elif date.strftime('%Y-%m-%d') >= '2022-03-20' and date.strftime('%Y-%m-%d') <= '2022-06-19':\n",
    "        return 'Spring 2022'\n",
    "    elif date.strftime('%Y-%m-%d') >= '2022-06-20' and date.strftime('%Y-%m-%d') <= '2022-09-21':\n",
    "        return 'Summer 2022'\n",
    "    elif date.strftime('%Y-%m-%d') >= '2022-09-22' and date.strftime('%Y-%m-%d') <= '2022-12-20':\n",
    "        return 'Fall 2022'\n",
    "    elif date.strftime('%Y-%m-%d') >= '2022-12-21' and date.strftime('%Y-%m-%d') <= '2023-03-19':\n",
    "        return 'Winter 2022'\n",
    "    elif date.strftime('%Y-%m-%d') >= '2023-03-20' and date.strftime('%Y-%m-%d') <= '2023-06-19':\n",
    "        return 'Spring 2023'\n",
    "    elif date.strftime('%Y-%m-%d') >= '2023-06-20' and date.strftime('%Y-%m-%d') <= '2023-09-21':\n",
    "        return 'Summer 2023'\n",
    "    else: \n",
    "        return 'Fall 2023'\n",
    "\n",
    "\n",
    "merged_df_post_omi['Season'] = merged_df_post_omi.index.map(get_season)\n",
    "\n",
    "merged_df_post_omi.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46285963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we've got our seasons and holidays, let's reset the index and make \"Sample Date\" a column.\n",
    "\n",
    "merged_df_post_omi.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629a21b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only thing left to add is school events, which in this case would just be normal school schedules and which\n",
    "# would map closely to seasons. Let's leave that category out.\n",
    "\n",
    "# Let's rename columns before saving our post-omicron data.  \n",
    "\n",
    "merged_df_post_omi.rename(columns={\n",
    "    'Concentration_SARS_CoV_2_gene_target_N1_CopiesL_': 'Gene Copies (N1/L)',\n",
    "    'Per_capita_SARS_CoV_2_load_N1_copies_per_day_per_population': 'Per Capita Gene Copies',\n",
    "    'Population_Served_estimated_': 'Population Served, estimated',\n",
    "    'Total_WRRF_Schoolaged_Pop': 'School-Aged Population'}, inplace=True)\n",
    "\n",
    "# merged_df_post_omi.to_csv('data/post_omi.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30575da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-Omicron Modelling with More Engineered Features\n",
    "\n",
    "post_omi_df = pd.read_csv('data/post_omi.csv')\n",
    "post_omi_df.sample(5)\n",
    "post_omi_df['Sample_Date'] = pd.to_datetime(post_omi_df['Sample_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e3d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_omi_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d1c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = []\n",
    "cat_cols = []  \n",
    "num_cols = []   \n",
    "\n",
    "for i in post_omi_df.columns:\n",
    "    if i == 'Gene Copies (N1/L)' or i == 'Holiday':\n",
    "        pass \n",
    "    elif post_omi_df[i].dtype == 'object':\n",
    "        cat_cols.append(i)\n",
    "    elif post_omi_df[i].dtype == 'datetime64[ns]':\n",
    "        date_cols.append(i)\n",
    "    elif post_omi_df[i].dtype == 'float64' or post_omi_df[i].dtype == 'int64':\n",
    "        num_cols.append(i)\n",
    "    else:\n",
    "        print(\"error\")\n",
    "        \n",
    "print(date_cols)\n",
    "print(cat_cols)\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccea8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = post_omi_df ['Gene Copies (N1/L)']\n",
    "\n",
    "X = post_omi_df.drop('Gene Copies (N1/L)', axis=1)\n",
    "\n",
    "X_train ,X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5187936f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9775790817147073\n",
      "0.9226426424514184\n"
     ]
    }
   ],
   "source": [
    "cat_preprocessor = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numeric_preprocessor = Pipeline([\n",
    "    ('selector', ColumnSelector(columns=num_cols)), \n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_preprocessor, cat_cols),\n",
    "    ('num', numeric_preprocessor, num_cols),\n",
    "])\n",
    "\n",
    "grad_2 = GradientBoostingRegressor(criterion='squared_error', learning_rate=0.1, loss='absolute_error', n_estimators=150, subsample=0.5, random_state=42)\n",
    "\n",
    "\n",
    "grad_2_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model',  grad_2)\n",
    "])\n",
    "\n",
    "grad_2_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grad_2_pipeline.predict(X_test)\n",
    "\n",
    "train_score = grad_2_pipeline.score(X_train, y_train)\n",
    "print(train_score)\n",
    "\n",
    "test_score = r2_score(y_test, y_pred)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16e08076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04186005296729049: Sample_Date\n",
      "0.03682010457750008: Holiday\n",
      "0.01437212568584682: School-Aged Population\n",
      "0.010258085107429012: WRRF_Name\n",
      "0.0066794820202109835: Season\n",
      "0.004935402389601626: Population Served, estimated\n",
      "0.0007449077153210352: Per Capita Gene Copies\n"
     ]
    }
   ],
   "source": [
    "grad_model = grad_2_pipeline.named_steps['model']\n",
    "features = []\n",
    "scores = []\n",
    "# Print the coefficients along with column names\n",
    "for feature_name, importance in zip(X.columns, grad_model.feature_importances_):\n",
    "    features.append(feature_name)\n",
    "    scores.append(importance)\n",
    "    \n",
    "ranked_scores = sorted(zip(scores, features), reverse=True)\n",
    "for score, feature in ranked_scores:\n",
    "    print(f'{score}: {feature}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d50e698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9775790817147073\n",
      "0.9226426424514184\n"
     ]
    }
   ],
   "source": [
    "# Let's drop date info as before.\n",
    "\n",
    "y = post_omi_df ['Gene Copies (N1/L)']\n",
    "\n",
    "X = post_omi_df.drop(columns=['Gene Copies (N1/L)', 'Sample_Date'], axis=1)\n",
    "\n",
    "X_train ,X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)\n",
    "\n",
    "cat_preprocessor = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numeric_preprocessor = Pipeline([\n",
    "    ('selector', ColumnSelector(columns=num_cols)), \n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_preprocessor, cat_cols),\n",
    "    ('num', numeric_preprocessor, num_cols),\n",
    "])\n",
    "\n",
    "grad_2 = GradientBoostingRegressor(criterion='squared_error', learning_rate=0.1, loss='absolute_error', n_estimators=150, subsample=0.5, random_state=42)\n",
    "\n",
    "\n",
    "grad_2_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model',  grad_2)\n",
    "])\n",
    "\n",
    "grad_2_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grad_2_pipeline.predict(X_test)\n",
    "\n",
    "train_score = grad_2_pipeline.score(X_train, y_train)\n",
    "print(train_score)\n",
    "\n",
    "test_score = r2_score(y_test, y_pred)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e2e171f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04186005296729049: WRRF_Name\n",
      "0.01437212568584682: Season\n",
      "0.010258085107429012: Per Capita Gene Copies\n",
      "0.0066794820202109835: Holiday\n",
      "0.004935402389601626: School-Aged Population\n",
      "0.0007449077153210352: Population Served, estimated\n"
     ]
    }
   ],
   "source": [
    "grad_model = grad_2_pipeline.named_steps['model']\n",
    "features = []\n",
    "scores = []\n",
    "# Print the coefficients along with column names\n",
    "for feature_name, importance in zip(X.columns, grad_model.feature_importances_):\n",
    "    features.append(feature_name)\n",
    "    scores.append(importance)\n",
    "    \n",
    "ranked_scores = sorted(zip(scores, features), reverse=True)\n",
    "for score, feature in ranked_scores:\n",
    "    print(f'{score}: {feature}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92be34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once more without Per Capita Gene Copies (daily) and Population Served, which tend towards colinearity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc959ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = post_omi_df ['Gene Copies (N1/L)']\n",
    "\n",
    "X = post_omi_df.drop(columns=['Gene Copies (N1/L)', 'Sample_Date', 'Per Capita Gene Copies', 'Population Served, estimated'], axis=1)\n",
    "\n",
    "X_train ,X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45865af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sample_Date']\n",
      "['WRRF_Name', 'Season']\n",
      "['School-Aged Population']\n"
     ]
    }
   ],
   "source": [
    "date_cols = []\n",
    "cat_cols = []  \n",
    "num_cols = []   \n",
    "\n",
    "\n",
    "num_cols = []   \n",
    "\n",
    "for i in post_omi_df.columns:\n",
    "    if i == 'Gene Copies (N1/L)' or i == 'Holiday' or i == 'Per Capita Gene Copies' or i == 'Population Served, estimated':\n",
    "        pass \n",
    "    elif post_omi_df[i].dtype == 'object':\n",
    "        cat_cols.append(i)\n",
    "    elif post_omi_df[i].dtype == 'datetime64[ns]':\n",
    "        date_cols.append(i)\n",
    "    elif post_omi_df[i].dtype == 'float64' or merged_df_post_omi[i].dtype == 'int64':\n",
    "        num_cols.append(i)\n",
    "    else:\n",
    "        print(\"error\")\n",
    "        \n",
    "print(date_cols)\n",
    "print(cat_cols)\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ba92c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21868701600462104\n",
      "0.22431025063267285\n"
     ]
    }
   ],
   "source": [
    "cat_preprocessor = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numeric_preprocessor = Pipeline([\n",
    "    ('selector', ColumnSelector(columns=num_cols)), \n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_preprocessor, cat_cols),\n",
    "    ('num', numeric_preprocessor, num_cols),\n",
    "])\n",
    "\n",
    "grad_2 = GradientBoostingRegressor(criterion='squared_error', learning_rate=0.1, loss='absolute_error', n_estimators=150, subsample=0.5, random_state=42)\n",
    "\n",
    "\n",
    "grad_2_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model',  grad_2)\n",
    "])\n",
    "\n",
    "grad_2_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grad_2_pipeline.predict(X_test)\n",
    "\n",
    "train_score = grad_2_pipeline.score(X_train, y_train)\n",
    "print(train_score)\n",
    "\n",
    "test_score = r2_score(y_test, y_pred)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29180b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029346903575089206: WRRF_Name\n",
      "0.02893346979770966: Holiday\n",
      "0.028000393386142745: School-Aged Population\n",
      "0.012760344393510042: Season\n"
     ]
    }
   ],
   "source": [
    "grad_model = grad_2_pipeline.named_steps['model']\n",
    "features = []\n",
    "scores = []\n",
    "# Print the coefficients along with column names\n",
    "for feature_name, importance in zip(X.columns, grad_model.feature_importances_):\n",
    "    features.append(feature_name)\n",
    "    scores.append(importance)\n",
    "    \n",
    "ranked_scores = sorted(zip(scores, features), reverse=True)\n",
    "for score, feature in ranked_scores:\n",
    "    print(f'{score}: {feature}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37e7ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This modelled data is quite weak. The variables that were important for pre-Omicron are clearly quite different than \n",
    "# with post-Omicron data.\n",
    "\n",
    "# Let's run a grid search on our best model. It is quite likely that the best parameters will be quite different\n",
    "# than with the pre-omicron data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59ee7d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sample_Date', 'WRRF_Name', 'Gene Copies (N1/L)',\n",
       "       'Per Capita Gene Copies', 'Population Served, estimated',\n",
       "       'School-Aged Population', 'Season', 'Holiday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_omi_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e063c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop date info as before.\n",
    "\n",
    "y = post_omi_df ['Gene Copies (N1/L)']\n",
    "\n",
    "X = post_omi_df.drop(columns=['Gene Copies (N1/L)', 'Sample_Date'], axis=1)\n",
    "\n",
    "X_train ,X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "y_train = np.log(y_train)\n",
    "y_test = np.log(y_test)\n",
    "\n",
    "cat_preprocessor = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numeric_preprocessor = Pipeline([\n",
    "    ('selector', ColumnSelector(columns=num_cols)), \n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_preprocessor, cat_cols),\n",
    "    ('num', numeric_preprocessor, num_cols),\n",
    "])\n",
    "\n",
    "grad_2 = GradientBoostingRegressor()\n",
    "\n",
    "grad_2_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model',  grad_2)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf5bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'model__learning_rate': [.01, .05, .1, .3],\n",
    "    'model__loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "    'model__n_estimators': [100, 150, 200, 250],\n",
    "    'model__subsample': [.3, .5, .7, 1.0],\n",
    "    'model__max_depth': [1, 3, 5, 7, 9, 11]\n",
    "    \n",
    "}\n",
    "                            \n",
    "grid_search_gbc = GridSearchCV(\n",
    "    estimator = grad_2_pipeline,  # pipeline \n",
    "    param_grid = param_grid,\n",
    "    cv= 5,\n",
    "    scoring='explained_variance'  # internal scoring term\n",
    ")\n",
    "\n",
    "grid_search_gbc.fit(X_train, y_train)\n",
    "\n",
    "cv_score = grid_search_gbc.best_score_\n",
    "test_score = r2_score(y_test, grid_search_gbc.predict(X_test))\n",
    "\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print(grid_search_gbc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f637135d",
   "metadata": {},
   "source": [
    "# Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccd0b65",
   "metadata": {},
   "source": [
    "\n",
    "### Adding holidays and seasons gave us a slight boost on our test scores, but these features are not as important as with pre-Omicron data. Clearly there are many other factors here that we are not accounting for. We assume the major missing variable is the average immunity - antibody duration in particular. Would also like to factor in office re-openings, changes in municipal, state, and federal policies, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddacf89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MCMPrime)",
   "language": "python",
   "name": "mcmprime"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
